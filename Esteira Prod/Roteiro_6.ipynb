{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTbXem+Uz70N32mQZHSE/g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rlrocha90/CursoVW/blob/main/Esteira%20Prod/Roteiro_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roteiro 6\n",
        "Produção"
      ],
      "metadata": {
        "id": "_YE07AysgYDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-transform"
      ],
      "metadata": {
        "id": "QJcXiXYdfgnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_transform as tft"
      ],
      "metadata": {
        "id": "q2F5bhGdfhV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "START_TOKEN_ID = 101\n",
        "END_TOKEN_ID = 102\n",
        "TFHUB_URL = (\"https://www.kaggle.com/models/tensorflow/bert/tensorFlow2/en-uncased-l-12-h-768-a-12/3\")"
      ],
      "metadata": {
        "id": "hK88e4ZAfjAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_bert_model(model_url=TFHUB_URL):\n",
        "  bert_layer = hub.KerasLayer(handle=model_url, trainable=False)\n",
        "  return bert_layer"
      ],
      "metadata": {
        "id": "V_iqMDJyfkma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _preprocessing_fn(inputs):\n",
        "  vocab_file_path = load_bert_model().resolved_object.vocab_file.asset_path\n",
        "\n",
        "  bert_tokenizer = tf_text.BertTokenizer(\n",
        "    vocab_lookup_table=vocab_file_path,\n",
        "    token_out_type=tf.int64,\n",
        "    lower_case=True)\n",
        "\n",
        "  text = inputs['message']\n",
        "  category = inputs['category']\n",
        "\n",
        "  # Normalize text\n",
        "  text = tf_text.normalize_utf8(text)\n",
        "\n",
        "  # Tokenization\n",
        "  tokens = bert_tokenizer.tokenize(text).merge_dims(1, -1)\n",
        "\n",
        "  # Add control tokens\n",
        "  tokens, input_type_ids = tf_text.combine_segments(tokens, start_of_sequence_id=START_TOKEN_ID, end_of_segment_id=END_TOKEN_ID)\n",
        "\n",
        "  # Token truncation / padding\n",
        "  tokens, input_mask_ids = tf_text.pad_model_inputs(tokens, max_seq_length=128)\n",
        "\n",
        "  # Convert categories to labels\n",
        "  labels = tft.compute_and_apply_vocabulary(label, vocab_filename=\"category\")\n",
        "\n",
        "  return {\n",
        "    \"labels\": labels,\n",
        "    \"input_ids\": tokens,\n",
        "    \"input_mask_ids\": input_mask_ids,\n",
        "    \"input_type_ids\": input_type_ids,\n",
        "  }"
      ],
      "metadata": {
        "id": "DQWba_FffmcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"jax[cpu]\" -f https://storage.googleapis.com/jax-releases/libtpu_releases.html -q\n",
        "!pip install --upgrade keras -q"
      ],
      "metadata": {
        "id": "GCJFrEn7foM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "import keras\n",
        "from keras.datasets import reuters\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras import layers\n",
        "num_words = 1000\n",
        "print(f'Keras version: {keras.__version__}\\n\\n')\n",
        "(reuters_train_x, reuters_train_y), (reuters_test_x, reuters_test_y) = reuters.load_data(num_words=num_words)\n",
        "n_labels = np.unique(reuters_train_y).shape[0]\n",
        "reuters_train_y = to_categorical(reuters_train_y, 46)\n",
        "reuters_test_y = to_categorical(reuters_test_y, 46)"
      ],
      "metadata": {
        "id": "vs8CYi9Jfr-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reuters_train_x = sequence.pad_sequences(reuters_train_x, maxlen=20)\n",
        "reuters_test_x = sequence.pad_sequences(reuters_test_x, maxlen=20)"
      ],
      "metadata": {
        "id": "LwXaM-OMfty9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = keras.Sequential(\n",
        "    [\n",
        "        layers.Embedding(num_words, 1000),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.Activation('relu'),\n",
        "        layers.Dense(46),\n",
        "        layers.Activation('softmax')\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "qvog2ZElfwGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "7J2PZ4BvfxgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs_model1\")\n",
        "model_1 = model1.fit(reuters_train_x, reuters_train_y,validation_data=(reuters_test_x, reuters_test_y),batch_size=128, epochs=20, verbose=1,callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "PbLdjCdLfzIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "# Open an embedded TensorBoard viewer\n",
        "%tensorboard --logdir ./logs_model1"
      ],
      "metadata": {
        "id": "yCxWznQNf0g_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = keras.Sequential(\n",
        "  [\n",
        "    layers.Embedding(num_words, 10),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Activation('relu'),\n",
        "    layers.Dense(46),\n",
        "    layers.Activation('softmax')\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "_J0-W1jRf3ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\",metrics=[\"accuracy\"])\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"./logs_model2\")\n",
        "model_2 = model2.fit(reuters_train_x, reuters_train_y, validation_data=(reuters_test_x, reuters_test_y), batch_size=128, epochs=20, verbose=1, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "LBFFekxnf3yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open an embedded TensorBoard viewer\n",
        "%tensorboard --logdir ./logs_model2"
      ],
      "metadata": {
        "id": "4z5FSE1nf5Px"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}